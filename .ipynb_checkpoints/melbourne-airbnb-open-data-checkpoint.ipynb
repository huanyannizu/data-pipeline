{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Melbourne airbnb open data analysis pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from sklearn.utils import shuffle\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#manually select columns might be useful\n",
    "category_features = ['room_type','cancellation_policy']\n",
    "bool_features = ['host_is_superhost', 'host_identity_verified','is_location_exact','has_availability','requires_license','instant_bookable',\n",
    "                 'require_guest_profile_picture','require_guest_phone_verification']\n",
    "numerical_features = ['accommodates', 'bathrooms', 'bedrooms', 'beds','guests_included', 'extra_people','minimum_nights', 'maximum_nights',\n",
    "                      'availability_30', 'availability_60', 'availability_90','availability_365','number_of_reviews','calculated_host_listings_count',\n",
    "                      'security_deposit', 'cleaning_fee','review_scores_rating','review_scores_accuracy','review_scores_cleanliness','review_scores_checkin',\n",
    "                      'review_scores_communication','review_scores_location','review_scores_value','reviews_per_month']\n",
    "special_features = ['latitude', 'longitude']\n",
    "target = ['price']\n",
    "\n",
    "# read in data by data types\n",
    "category_data = pd.read_csv('cleansed_listings_dec18.csv', usecols = category_features, dtype = str)\n",
    "boolean_data = pd.read_csv('cleansed_listings_dec18.csv', usecols = bool_features, dtype = str)\n",
    "boolean_data = boolean_data.replace({'t': True, 'f': False})\n",
    "numerical_data = pd.read_csv('cleansed_listings_dec18.csv', usecols = numerical_features)\n",
    "special_data = pd.read_csv('cleansed_listings_dec18.csv', usecols = special_features)\n",
    "target_data = pd.read_csv('cleansed_listings_dec18.csv', usecols = target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12213, 37)\n"
     ]
    }
   ],
   "source": [
    "# concatinate previously read data into one table for further cleaning purpose\n",
    "data = pd.concat([target_data,category_data,boolean_data,numerical_data,special_data], axis=1, sort=False)\n",
    "data = data.dropna(axis=0).reset_index(drop=True) #drop rows with missing values\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    12213.000000\n",
      "mean       148.092442\n",
      "std        119.555421\n",
      "min          0.000000\n",
      "50%        125.000000\n",
      "80%        188.000000\n",
      "90%        251.000000\n",
      "95%        338.400000\n",
      "max       3000.000000\n",
      "Name: price, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# check outliers of target variable and remove them\n",
    "print(data.price.describe(percentiles=[0.8, 0.9, 0.95]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11701, 37)\n"
     ]
    }
   ],
   "source": [
    "# only keep rows with price smaller than 350 to remove outliers\n",
    "data = data[data['price'] <= 350].reset_index(drop=True)\n",
    "data = shuffle(data).reset_index(drop=True)\n",
    "print(data.shape)\n",
    "\n",
    "# save the cleaned data\n",
    "data.to_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "host_is_superhost 21.758368231419446 3.1266403617993963e-06\n",
      "host_identity_verified 2.3431864182879885 0.12585896755737352\n",
      "is_location_exact 19.44145790834253 1.0465629644317097e-05\n",
      "has_availability nan nan\n",
      "requires_license nan nan\n",
      "instant_bookable 11.43891845031981 0.0007215726299179188\n",
      "require_guest_profile_picture 2.1372634831099164 0.14378498843843382\n",
      "require_guest_phone_verification 16.99786425840132 3.7680230616096076e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scipy/stats/stats.py:2923: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ssbn += _square_of_sums(a - offset) / float(len(a))\n"
     ]
    }
   ],
   "source": [
    "#selecting boolean features: apply ANOVA to find important contributers to target variable\n",
    "drop_bool = []\n",
    "for c in bool_features:\n",
    "    F, p_value = stats.f_oneway(data['price'][data[c] == False], data['price'][data[c] == True])\n",
    "    print(c,F, p_value)\n",
    "    # keep significant features (p_value <= 0.05)\n",
    "    if p_value > 0.05 or np.isnan(p_value): drop_bool.append(c)\n",
    "\n",
    "data = data.drop(columns = drop_bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step would be to remove outliers of category features. We would check the frequencies of each category of a category feature, and remove the ones with low frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entire home/apt    8739\n",
      "Private room       2871\n",
      "Shared room          91\n",
      "Name: room_type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# frequency checking of feature room_type\n",
    "print(data['room_type'].value_counts())\n",
    "\n",
    "# remove rows with 'Shared room'\n",
    "a = ['Entire home/apt','Private room']\n",
    "data = data[data['room_type'].isin(a)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strict_14_with_grace_period    6003\n",
      "moderate                       3650\n",
      "flexible                       1947\n",
      "super_strict_60                   9\n",
      "super_strict_30                   1\n",
      "Name: cancellation_policy, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# frequency checking of feature cancellation_policy\n",
    "print(data['cancellation_policy'].value_counts())\n",
    "\n",
    "# remove rows with 'super_strict_60' and 'super_strict_30'\n",
    "a = ['strict_14_with_grace_period','moderate','flexible']\n",
    "data = data[data['cancellation_policy'].isin(a)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding of category features and keep significant features\n",
    "for c in category_features:\n",
    "    one_hot = pd.get_dummies(data[c])\n",
    "    uniq = pd.unique(data[c])\n",
    "    F, p_value = stats.f_oneway(*(data[data[c] == u]['price'] for u in uniq))\n",
    "    # print(c, F, p_value)\n",
    "    data = data.drop(columns=c, axis=1)\n",
    "    if p_value <= 0.05:\n",
    "        data = data.join(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accommodates 0.5953974276860057\n",
      "bathrooms 0.3800754224913949\n",
      "bedrooms 0.5810455200605964\n",
      "beds 0.518481795327234\n",
      "guests_included 0.4546713235190234\n",
      "extra_people 0.11557399086938681\n",
      "minimum_nights 0.0015384684702487589\n",
      "maximum_nights -0.006295478275747637\n",
      "availability_30 0.037911879959962085\n",
      "availability_60 0.05153998219382068\n",
      "availability_90 0.06448242126617998\n",
      "availability_365 0.1509974215537623\n",
      "number_of_reviews 0.023953590024643256\n",
      "calculated_host_listings_count 0.07539909143539071\n",
      "security_deposit 0.19324002873300947\n",
      "cleaning_fee 0.455901683936846\n",
      "review_scores_rating 0.03625362171436523\n",
      "review_scores_accuracy 0.020461172948739444\n",
      "review_scores_cleanliness 0.06157245194999848\n",
      "review_scores_checkin -0.014602265458875122\n",
      "review_scores_communication 0.01682521505856605\n",
      "review_scores_location 0.106704405325539\n",
      "review_scores_value -0.034731448574602065\n",
      "reviews_per_month 0.020056101858792887\n"
     ]
    }
   ],
   "source": [
    "# numerical features selection: calculate correlations between numerical varaibles \n",
    "# and target variable, keep features with correlation coefficient larger than 0.4\n",
    "for c in numerical_features:\n",
    "    corr = np.corrcoef(data['price'], data[c])\n",
    "    print(c, corr[0,1])\n",
    "    if abs(corr[0,1]) < 0.4:\n",
    "        data = data.drop(columns=c, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training / testing spliting\n",
    "train_percentage = 0.8\n",
    "num_train = math.ceil(data.shape[0] * train_percentage)\n",
    "\n",
    "train_x = data.drop(columns = ['price'])[:num_train]\n",
    "train_y = data['price'][:num_train]\n",
    "test_x = data.drop(columns = ['price'])[num_train:]\n",
    "test_y = data['price'][num_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum depth:  5\n",
      "training error:  29.41783414146766\n",
      "testing error:  29.602742690017784\n",
      "=============================\n",
      "maximum depth:  6\n",
      "training error:  28.42344551292941\n",
      "testing error:  28.969096289882565\n",
      "=============================\n",
      "maximum depth:  7\n",
      "training error:  27.463930635029936\n",
      "testing error:  28.54088336055326\n",
      "=============================\n",
      "maximum depth:  8\n",
      "training error:  26.41892865436612\n",
      "testing error:  28.125392659971737\n",
      "=============================\n",
      "maximum depth:  9\n",
      "training error:  25.278408740042007\n",
      "testing error:  27.780983059668554\n",
      "=============================\n",
      "maximum depth:  10\n",
      "training error:  24.092234718752145\n",
      "testing error:  27.578051462071162\n",
      "=============================\n"
     ]
    }
   ],
   "source": [
    "# Fit RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "for d in [5,6,7,8,9,10]:\n",
    "    clf = RandomForestRegressor(n_estimators=100, max_depth=d, random_state=0)\n",
    "    clf.fit(train_x, train_y)\n",
    "    pred = clf.predict(train_x)\n",
    "    print('maximum depth: ', d)\n",
    "    print('training error: ', sum(abs(train_y - pred)) / pred.shape[0])\n",
    "    pred = clf.predict(test_x)\n",
    "    print('testing error: ', sum(abs(test_y - pred)) / pred.shape[0])\n",
    "    print('=============================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of neighbors:  3\n",
      "31.577442528735684\n",
      "======================\n",
      "num of neighbors:  4\n",
      "31.091810344827586\n",
      "======================\n",
      "num of neighbors:  5\n",
      "30.548362068965517\n",
      "======================\n",
      "num of neighbors:  6\n",
      "30.305172413793116\n",
      "======================\n",
      "num of neighbors:  7\n",
      "30.28768472906401\n",
      "======================\n",
      "num of neighbors:  8\n",
      "30.153178879310346\n",
      "======================\n",
      "num of neighbors:  9\n",
      "30.105890804597728\n",
      "======================\n",
      "num of neighbors:  10\n",
      "30.088232758620705\n",
      "======================\n"
     ]
    }
   ],
   "source": [
    "from sklearn import neighbors\n",
    "for k in [3,4,5,6,7,8,9,10]:\n",
    "    model = neighbors.KNeighborsRegressor(n_neighbors = k)\n",
    "    model.fit(train_x,train_y)\n",
    "    pred = model.predict(test_x)\n",
    "    print('num of neighbors: ', k)\n",
    "    print(sum(abs(test_y - pred)) / pred.shape[0])\n",
    "    print('======================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigquery basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BigQuery organization\n",
    "BigQuery is structured as a hierarchy with 4 levels: projects, datasets, tables, and jobs. In the following example, testing-236601 is the project nanme, babynames, bqml_tutorial and melbourne_airbnb are datasets of the project, data is the table of dataset melbourne_airbnb. Bigquery can be accessed with web browser, command line tools, third party tools such as Tableau, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"structure.png\" alt=\"drawing\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Projects are the top-level containers that store the data. Each project has a name, ID, and number as identifiers.\n",
    "- Datasets allow you to organize and control access to your tables. A table must belong to a dataset.\n",
    "- Tables contain your data loaded into BigQuery. Here in our example, table data contains the generated cleaned airbnb data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each table has a schema that describes the data contained in the table, including field names, types, mode and descriptions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"schema.png\" alt=\"drawing\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BigQuery uses a SQL-like language for querying and manipulating data. The query results are presented in the section Results.\n",
    "\n",
    "Basic queries contain the following components:\n",
    "- SELECT (required): identifies the columns to be included in the query\n",
    "- FROM (required): the table that contains the columns in the SELECT statement\n",
    "- WHERE: a condition for filtering records\n",
    "- ORDER BY: how to sort the result set\n",
    "- LIMIT: number of rows to be presented from the query results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"query.png\" alt=\"drawing\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resources:\n",
    "- https://cloud.google.com/bigquery/\n",
    "- https://cloud.google.com/docs/tutorials#%22google+analytics%22+bigquery\n",
    "- https://www.w3schools.com/sql/default.asp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
